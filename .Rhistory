subsample = 0.6,
booster = 'gbtree',
early_stopping_round = 20,
colsample_bytree = 0.7,
seed = 1,
eval_metric = "merror",
objective = "multi:softmax",
num_class = 5,
)
pred <- predict(xgb, test) + 1
accuracy(docvars(test, 'label'), pred)
}
xgb_model(train_dfm, test_dfm, 5, 0.2, 10)
# use a smaller subset to perform analysis
train <- train[1:6500,]
set.seed(162)
# size of the sample
sample <- floor(0.7*nrow(train))
train_dfm <- train %>%
corpus() %>%
dfm(remove_punct=TRUE,
remove=stopwords("english")) %>%
dfm_sample(size=sample,
margin='documents')
test_dfm <- train %>%
corpus() %>%
corpus_subset(!docnames(.) %in% docnames(train_dfm)) %>%
dfm(remove_punct=TRUE,
remove=stopwords("english")) %>%
# make sure the dfm has all the features train dfm has
dfm_select(pattern=train_dfm,
selection='keep')
train_slim <- dfm_trim(train_dfm,
sparsity=0.95,
min_docfreq = 0.05,
docfreq_type = "prop",
verbose = TRUE)
# test set
test_slim <- dfm_match(test_dfm,
features = featnames(train_slim))
# accuracy function for evaluation
accuracy <- function(ypred, y){
tab <- table(ypred, y)
return(sum(diag(tab))/sum(tab))
}
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_dfm, test_dfm, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
chi2 <- dfm_group(train_dfm,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
chi2$feature
featnames(train_slim)
chi2$feature
featnames(train_slim)
# use a smaller subset to perform analysis
train <- train[1:6500,]
set.seed(162)
# size of the sample
sample <- floor(0.7*nrow(train))
train_dfm <- train %>%
corpus() %>%
dfm(remove_punct=TRUE,
removeNumbers = TRUE
remove=stopwords("english")) %>%
# use a smaller subset to perform analysis
train <- train[1:6500,]
set.seed(162)
# size of the sample
sample <- floor(0.7*nrow(train))
train_dfm <- train %>%
corpus() %>%
dfm(remove_punct=TRUE,
removeNumbers = TRUE,
remove=stopwords("english")) %>%
dfm_sample(size=sample,
margin='documents')
test_dfm <- train %>%
corpus() %>%
corpus_subset(!docnames(.) %in% docnames(train_dfm)) %>%
dfm(remove_punct=TRUE,
remove=stopwords("english")) %>%
# make sure the dfm has all the features train dfm has
dfm_select(pattern=train_dfm,
selection='keep')
train_slim <- dfm_trim(train_dfm,
sparsity=0.95,
min_docfreq = 0.05,
docfreq_type = "prop",
verbose = TRUE)
# test set
test_slim <- dfm_match(test_dfm,
features = featnames(train_slim))
# accuracy function for evaluation
accuracy <- function(ypred, y){
tab <- table(ypred, y)
return(sum(diag(tab))/sum(tab))
}
chi2 <- dfm_group(train_slin,
groups = 'label') %>%
textstat_keyness()
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
# the model and prediction with full feature set
nb_model <- function(train, test){
print(train)
nb <- textmodel_nb(train,
docvars(train, 'label'),
prior='docfreq')
pred <- predict(nb, newdata=test)
# scoring
accuracy(docvars(test, 'label'), pred)
}
nb_model(train_dfm, test_dfm)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
nb_model(train_slim, test_slim)
nb_model(train_chi, test_chi)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
library(randomForest)
rf_model <- function(train, test, try, ntree){
df_train <- convert(train, to='data.frame')[,-1]
df_test <- convert(test, to='data.frame')[,-1]
rf <- randomForest(x=df_train,
y=factor(docvars(train, 'label')),
xtest=df_test,
ytest=factor(docvars(test, 'label')),
importance=TRUE,
mtry=try,
ntree=ntree,
keep.forest=TRUE
)
pred <- predict(rf, df_test, type="response")
accuracy(docvars(test, 'label'), pred)
}
rf_model(train_slim, test_slim, 20, 100)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 100)
rf_model(train_chi, test_chi, 20, 100)
nb_model(train_slim, test_slim)
nb_model(train_chi, test_chi)
log_model <- function(train, test, fold){
registerDoMC(cores=3)
ridge <- cv.glmnet(train, factor(docvars(train, 'label')),
family="multinomial", alpha=0, nfolds=fold, parallel=TRUE, intercept=TRUE,
type.measure="class")
pred <- predict(ridge, test, type="class")
accuracy(docvars(test, 'label'), pred)
}
log_model(train_slim, test_slim, 30)
log_model(train_chi, test_chi, 30)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
train_tfidf <- train_slim %>%
dfm_tfidf(scheme_tf = "count",
scheme_df = "inverse",
base = 10,
force = FALSE)
test_tfidf <- dfm_match(test_dfm,
features = featnames(train_tfidf))
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 100)
rf_model(train_chi, test_chi, 20, 100)
rf_model(train_tfidf, test_tfidf, 20, 100)
nb_model(train_slim, test_slim)
nb_model(train_chi, test_chi)
nb_model(train_tfidf, test_tfidf)
# the model and prediction with full feature set
nb_model <- function(train, test){
print(train)
nb <- textmodel_nb(train,
docvars(train, 'label'),
prior='docfreq',
force = TRUE)
pred <- predict(nb, newdata=test)
# scoring
accuracy(docvars(test, 'label'), pred)
}
nb_model(train_dfm, test_dfm)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 10)
rf_model(train_chi, test_chi, 20, 10)
rf_model(train_tfidf, test_tfidf, 20, 10)
nb_model(train_slim, test_slim)
nb_model(train_tfidf, test_tfidf)
log_model(train_slim, test_slim, 30)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 10)
rf_model(train_chi, test_chi, 20, 10)
rf_model(train_tfidf, test_tfidf, 20, 10)
nb_model(train_slim, test_slim)
log_model <- function(train, test, fold){
registerDoMC(cores=3)
ridge <- cv.glmnet(train, factor(docvars(train, 'label')),
family="multinomial", alpha=1, nfolds=fold, parallel=TRUE, intercept=TRUE,
type.measure="class")
pred <- predict(ridge, test, type="class")
accuracy(docvars(test, 'label'), pred)
}
log_model(train_slim, test_slim, 30)
# the model and prediction with full feature set
nb_model <- function(train, test){
print(train)
nb <- textmodel_nb(train,
docvars(train, 'label'),
prior='docfreq')
pred <- predict(nb, newdata=test)
# scoring
accuracy(docvars(test, 'label'), pred)
}
nb_model(train_dfm, test_dfm)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 10)
rf_model(train_chi, test_chi, 20, 10)
rf_model(train_tfidf, test_tfidf, 20, 10)
nb_model(train_slim, test_slim)
nb_model(train_chi, test_chi)
nb_model(train_tfidf, test_tfidf)
log_model(train_slim, test_slim, 30)
chi2 <- dfm_group(train_slim,
groups = 'label') %>%
textstat_keyness()
chi2$chi2 <- abs(chi2$chi2)
chi2 <- chi2[order(chi2$chi2, decreasing = TRUE), ]
head(chi2,10)
train_chi <- train_dfm %>%
dfm_select(chi2$feature)
test_chi <- dfm_match(test_dfm,
features = featnames(train_chi))
xgb_model(train_slim, test_slim, 5, 0.2, 10)
xgb_model(train_chi, test_chi, 5, 0.2, 10)
xgb_model(train_tfidf, test_tfidf, 5, 0.2, 10)
rf_model(train_slim, test_slim, 20, 50)
rf_model(train_chi, test_chi, 20, 50)
rf_model(train_tfidf, test_tfidf, 20, 50)
nb_model(train_slim, test_slim)
nb_model(train_chi, test_chi)
log_model(train_slim, test_slim, 30)
log_model(train_chi, test_chi, 30)
log_model(train_tfidf, test_tfidf, 30)
install.packages("text2vec")
knitr::opts_chunk$set(echo = TRUE)
# libraries
library(tidyverse)
library(quanteda)
library(caret)
library(xgboost)
library(randomForest)
library(glmnet)
library(parallel)
library(parallelMap)
library(text2vec)
require(doMC)
# importing the data
train <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_data.csv")
label <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_label.csv")
train <- merge(x=train, y=label, by='trn_id')
# set the memory limit to whatever is possible
memory.limit(size = NA)
# quanteda options settings
quanteda_options(verbose = TRUE)
quanteda_options(threads = 8)
# use all cores
parallelStartSocket(cpus = detectCores())
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(train$text,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$trn_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
train_dfm
knitr::opts_chunk$set(echo = TRUE)
# libraries
library(tidyverse)
library(quanteda)
library(caret)
library(xgboost)
library(randomForest)
library(glmnet)
library(parallel)
library(parallelMap)
library(text2vec)
require(doMC)
# importing the data
train <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_data.csv")
label <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_label.csv")
train <- merge(x=train, y=label, by='trn_id')
# set the memory limit to whatever is possible
memory.limit(size = NA)
# quanteda options settings
quanteda_options(verbose = TRUE)
quanteda_options(threads = 8)
# use all cores
parallelStartSocket(cpus = detectCores())
train_dfm
knitr::opts_chunk$set(echo = TRUE)
# libraries
library(tidyverse)
library(quanteda)
library(caret)
library(xgboost)
library(randomForest)
library(glmnet)
library(parallel)
library(parallelMap)
library(text2vec)
require(doMC)
# importing the data
train <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_data.csv")
label <- read_csv("~/Google Drive/Monash/Semester 3/FIT5149/Assessment/Assessment 2/src/Training Dataset/train_label.csv")
train <- merge(x=train, y=label, by='trn_id')
# set the memory limit to whatever is possible
memory.limit(size = NA)
# quanteda options settings
quanteda_options(verbose = TRUE)
quanteda_options(threads = 8)
# use all cores
parallelStartSocket(cpus = detectCores())
# use a smaller subset to perform analysis
train <- train[1:6500,]
set.seed(162)
# size of the sample
sample <- floor(0.7*nrow(train))
train_dfm <- train %>%
corpus() %>%
dfm(remove_punct=TRUE,
removeNumbers = TRUE,
remove=stopwords("english")) %>%
dfm_sample(size=sample,
margin='documents')
test_dfm <- train %>%
corpus() %>%
corpus_subset(!docnames(.) %in% docnames(train_dfm)) %>%
dfm(remove_punct=TRUE,
remove=stopwords("english")) %>%
# make sure the dfm has all the features train dfm has
dfm_select(pattern=train_dfm,
selection='keep')
train_slim <- dfm_trim(train_dfm,
sparsity=0.95,
min_docfreq = 0.05,
docfreq_type = "prop",
verbose = TRUE)
# test set
test_slim <- dfm_match(test_dfm,
features = featnames(train_slim))
# accuracy function for evaluation
accuracy <- function(ypred, y){
tab <- table(ypred, y)
return(sum(diag(tab))/sum(tab))
}
score(model1)
# prediction
predictions <- predict(model,
sentences = test_df$text,
unlock_empty_predictions=TRUE) %>%
sapply(names)
shiny::runApp('~/Google Drive/Monash/Semester 3/FIT5147/Assessment/Visualisation Project/Shiny_app/mel_housing')
install.packages("shinyjs")
library(shinyjs)
shiny::runApp('~/Google Drive/Monash/Semester 3/FIT5147/Assessment/Visualisation Project/Shiny_app/mel_housing')
shiny::runApp()
# read the dataset
house <- read.csv('./housing.csv')
# set current directory to the script executing this code
cwd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(cwd)
# read the dataset
house <- read.csv('./housing.csv')
